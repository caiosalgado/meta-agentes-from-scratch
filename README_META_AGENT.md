# LLM Meta Agent ğŸ¤–

Sistema avanÃ§ado de criaÃ§Ã£o automÃ¡tica de agentes LLM especializados com pipelines inteligentes.

## ğŸ“‹ VisÃ£o Geral

O `LLM_Meta_Agent` Ã© um agente de IA que cria outros agentes de IA. Ele usa tÃ©cnicas avanÃ§adas de engenharia de prompts e aprendizado por experiÃªncia para gerar pipelines de agentes que maximizam a acurÃ¡cia em tarefas especÃ­ficas.

### ğŸ¯ CaracterÃ­sticas Principais

- **CriaÃ§Ã£o AutomÃ¡tica**: Gera cÃ³digo executÃ¡vel para novos agentes
- **Pipelines Inteligentes**: Suporta mÃºltiplas arquiteturas (Sequential, Debate, Reflection, etc.)
- **Aprendizado ContÃ­nuo**: MantÃ©m histÃ³rico de performance e aprende com sucessos/falhas
- **Teste Automatizado**: Executa 10 testes por agente para estatÃ­sticas confiÃ¡veis
- **MÃºltiplos Modelos**: Suporta 8 modelos diferentes (phi4, gemma3, qwen3)

## ğŸš€ InstalaÃ§Ã£o

```bash
# Instalar dependÃªncias
uv add aisuite langchain langchain-core

# Verificar se ollama estÃ¡ rodando
ollama list
```

## ğŸ’¡ Como Funciona

### 1. Arquiteturas Suportadas

- **Single Agent**: Um agente especializado
- **Sequential Pipeline**: Agente1 â†’ Agente2 â†’ ... â†’ AgentN
- **Debate Pipeline**: MÃºltiplos especialistas â†’ DecisÃ£o final
- **Reflection Pipeline**: Agente principal â†” Agente revisor
- **Hierarchical**: Agente coordenador + agentes especializados

### 2. Sistema de Aprendizado

O meta-agente mantÃ©m um histÃ³rico permanente (`agent_history.json`) com:
- Performance de cada agente (acurÃ¡cia + tempo)
- ConfiguraÃ§Ãµes que funcionaram/falharam
- PadrÃµes de erro identificados
- Exemplos funcionais para inspiraÃ§Ã£o

### 3. CritÃ©rios de SeleÃ§Ã£o

1. **AcurÃ¡cia** (prioridade mÃ¡xima)
2. **Tempo de execuÃ§Ã£o** (critÃ©rio de desempate)
3. **Robustez** (consistÃªncia entre mÃºltiplos testes)

## ğŸ“– Uso BÃ¡sico

### Exemplo Simples

```python
from llm_meta_agent import LLM_Meta_Agent

# Criar meta-agente
meta_agent = LLM_Meta_Agent(
    model="ollama:gemma3:4b",
    temperatura=0.3
)

# Definir tarefa
task = """
Criar um agente especialista em problemas de strings.
Deve ser excelente em:
- VerificaÃ§Ã£o de palÃ­ndromos
- ManipulaÃ§Ã£o de texto
- AnÃ¡lise de padrÃµes
"""

# Gerar cÃ³digo do agente
agent_spec = meta_agent.generate_agent_code(task)
print(f"Nome: {agent_spec['name']}")
print(f"CÃ³digo: {agent_spec['code']}")
```

### Exemplo Completo (com Teste)

```python
# Criar e testar agente completo
result = meta_agent.create_and_evaluate_agent(task)

if result["success"]:
    agent = result["agent"]
    print(f"AcurÃ¡cia: {agent['performance']['accuracy']:.1f}%")
    print(f"Tempo: {agent['performance']['avg_execution_time']:.2f}s")
```

## ğŸ”§ API Completa

### MÃ©todos Principais

```python
# Criar meta-agente
meta_agent = LLM_Meta_Agent(
    model="ollama:qwen3:32b",      # Modelo para o meta-agente
    history_file="agent_history.json",  # Arquivo de histÃ³rico
    temperatura=0.3                 # Temperatura para geraÃ§Ã£o
)

# Gerar cÃ³digo de agente
agent_spec = meta_agent.generate_agent_code(task_explicacao)

# Testar pipeline mÃºltiplas vezes
performance = meta_agent.test_pipeline_multiple_times(code, runs=10)

# Fluxo completo: gerar â†’ testar â†’ salvar
result = meta_agent.create_and_evaluate_agent(task_explicacao)

# EstatÃ­sticas do histÃ³rico
stats = meta_agent.get_agent_statistics()

# Top agentes por performance
top_agents = meta_agent.list_top_agents(5)
```

### Estrutura de Resposta

```python
# agent_spec (generate_agent_code)
{
    "name": "Nome do agente/pipeline",
    "pensamento": "RaciocÃ­nio sobre a arquitetura",
    "code": "CÃ³digo Python executÃ¡vel"
}

# performance (test_pipeline_multiple_times)
{
    "accuracy": 85.5,              # AcurÃ¡cia mÃ©dia (%)
    "avg_execution_time": 2.3,     # Tempo mÃ©dio (segundos)
    "successful_runs": 8,          # Runs bem-sucedidos
    "total_runs": 10,              # Total de runs
    "all_accuracies": [80, 90, ...], # Todas as acurÃ¡cias
    "all_execution_times": [2.1, 2.5, ...] # Todos os tempos
}
```

## ğŸ§ª Exemplos de Uso

### 1. Executar Exemplo Simples

```bash
python exemplo_meta_agent.py
```

### 2. Executar Testes Completos

```bash
python teste_meta_agent.py
```

### 3. Criar Agente Personalizado

```python
task = """
Criar um pipeline de debate com 3 especialistas:
1. Especialista em algoritmos
2. Especialista em estruturas de dados  
3. Especialista em otimizaÃ§Ã£o

Use diferentes modelos e temperaturas para cada especialista.
"""

result = meta_agent.create_and_evaluate_agent(task)
```

## ğŸ“Š Monitoramento

### Verificar HistÃ³rico

```python
# EstatÃ­sticas gerais
stats = meta_agent.get_agent_statistics()
print(f"Total: {stats['total_agents']}")
print(f"Funcionais: {stats['functional_agents']}")
print(f"Alta performance: {stats['high_performance_agents']}")

# Top performers
for i, agent in enumerate(meta_agent.list_top_agents(3), 1):
    print(f"{i}. {agent['name']}: {agent['performance']['accuracy']:.1f}%")
```

### Exemplos de Aprendizado

```python
# Ver exemplos funcionais (para inspiraÃ§Ã£o)
functional = meta_agent.get_functional_examples(3)

# Ver exemplos problemÃ¡ticos (para evitar)
problematic = meta_agent.get_non_functional_examples(3)
```

## ğŸ›ï¸ ConfiguraÃ§Ãµes AvanÃ§adas

### Modelos DisponÃ­veis

```python
available_models = [
    "ollama:phi4:latest",
    "ollama:gemma3:4b",
    "ollama:gemma3:12b", 
    "ollama:gemma3:27b",
    "ollama:qwen3:4b",
    "ollama:qwen3:14b",
    "ollama:qwen3:30b",
    "ollama:qwen3:32b"
]
```

### EstratÃ©gias de Temperatura

- **Baixa (0.1-0.3)**: Para precisÃ£o e consistÃªncia
- **MÃ©dia (0.4-0.6)**: Para equilÃ­brio
- **Alta (0.7-0.9)**: Para criatividade e exploraÃ§Ã£o

### CritÃ©rios de Performance

- **Funcional**: AcurÃ¡cia â‰¥ 30%
- **Alta Performance**: AcurÃ¡cia â‰¥ 70%
- **Tempo AceitÃ¡vel**: < 10 segundos por problema

## ğŸ” Troubleshooting

### Problemas Comuns

1. **Erro de importaÃ§Ã£o**: Verificar se `llm_agent.py` existe
2. **Modelo nÃ£o encontrado**: Verificar se ollama estÃ¡ rodando
3. **Timeout**: Aumentar timeout no cliente aisuite
4. **JSON invÃ¡lido**: Meta-agente tentarÃ¡ extrair JSON automaticamente

### Debug

```python
# Testar sÃ³ geraÃ§Ã£o (sem execuÃ§Ã£o)
agent_spec = meta_agent.generate_agent_code(task)
print(agent_spec['code'])

# Testar execuÃ§Ã£o manual
exec(agent_spec['code'])
```

## ğŸ“ˆ Roadmap

- [ ] Suporte a mais tipos de problemas (nÃ£o sÃ³ LeetCode)
- [ ] Interface web para visualizaÃ§Ã£o
- [ ] MÃ©tricas avanÃ§adas de performance
- [ ] Auto-tuning de hiperparÃ¢metros
- [ ] IntegraÃ§Ã£o com mais modelos LLM

## ğŸ¤ ContribuiÃ§Ã£o

1. Fork o projeto
2. Crie uma branch para sua feature
3. Commit suas mudanÃ§as
4. Push para a branch
5. Abra um Pull Request

---

**Desenvolvido com â¤ï¸ para maximizar a inteligÃªncia artificial atravÃ©s de colaboraÃ§Ã£o entre agentes.** 